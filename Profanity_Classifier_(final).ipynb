{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 욕설 분류기\n",
    "---------\n",
    "## CNN을 이용한 인터넷 채팅상의 욕설 분류 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "import hgtk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "## 1) 전처리\n",
    "### 사용할 초성, 중성, 종성 리스트 합본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkma = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jong_list = hgtk.const.JONG[1:]\n",
    "jamo = (hgtk.const.CHO,hgtk.const.JOONG,tuple(jong_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(raw_sentence):\n",
    "    noun_and_unknown = []\n",
    "    for word in kkma.pos(raw_sentence):\n",
    "        if word[1] == \"NNG\" or word[1] == \"UN\":\n",
    "            noun_and_unknown.append(word[0])\n",
    "    decompose_sentence = \"\".join(noun_and_unknown)\n",
    "    count = len(decompose_sentence)\n",
    "    range_list = [(0,5)]\n",
    "    if count > 5:\n",
    "        i = 0\n",
    "        while (i+5) < count:\n",
    "            i += 2\n",
    "            range_list.append((i,i+5))\n",
    "    decom_list = []\n",
    "    for s,t in range_list:\n",
    "        decom_list.append(hgtk.text.decompose(decompose_sentence[s:t]))\n",
    "    return decom_list, len(decom_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a,b= process_sentence(\"이 씹새끼가 어디서 약을 팔어 씹ㅏㄹ새끼야\")  \n",
    "print(a,b)\n",
    "\n",
    "------\n",
    "['ㅆㅣㅂᴥㅅㅐᴥㄲㅣᴥㅇㅑㄱᴥㅍㅏㄹᴥ',  \n",
    "'ㄲㅣᴥㅇㅑㄱᴥㅍㅏㄹᴥㅆㅣㅂᴥㅏᴥ',  \n",
    "'ㅍㅏㄹᴥㅆㅣㅂᴥㅏᴥㄹᴥㅅㅐᴥ',  \n",
    "'ㅏᴥㄹᴥㅅㅐᴥㄲㅣᴥ'] 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def let2mat(processed):\n",
    "    result_np = np.zeros((5,3))\n",
    "    i, index = 0, 0\n",
    "    for c in processed:\n",
    "        if c == 'ᴥ':\n",
    "            index += 1\n",
    "            i = 0\n",
    "            continue\n",
    "        if (c not in jamo[i]):\n",
    "            i += 1\n",
    "        result_np[index,i] = jamo[i].index(c) + 1 #공백과 첫번째 인덱스를 구분하기 위해서\n",
    "        i += 1\n",
    "    return result_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(raw_sentence):\n",
    "    a,b = process_sentence(raw_sentence)\n",
    "    result = let2mat(a[0])\n",
    "    for i in range(1,b):\n",
    "        if result.ndim == 2:\n",
    "            result = np.r_[[result],[let2mat(a[i])]]\n",
    "            continue\n",
    "        result = np.r_[result,[let2mat(a[i])]]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a,b = process_sentence(\"이 씹새끼가 어디서 약을 팔어 씹ㅏㄹ새끼야\")\n",
    "print(a,b)\n",
    "process(\"이 씹새끼가 어디서 약을 팔어 씹ㅏㄹ새끼야\")\n",
    "\n",
    "-----\n",
    "['ㅆㅣㅂᴥㅅㅐᴥㄲㅣᴥㅇㅑㄱᴥㅍㅏㄹᴥ', 'ㄲㅣᴥㅇㅑㄱᴥㅍㅏㄹᴥㅆㅣㅂᴥㅏᴥ', 'ㅍㅏㄹᴥㅆㅣㅂᴥㅏᴥㄹᴥㅅㅐᴥ', 'ㅏᴥㄹᴥㅅㅐᴥㄲㅣᴥ'] 4  \n",
    "\n",
    "      [[[11., 21., 17.],  \n",
    "        [10.,  2.,  0.],  \n",
    "        [ 2., 21.,  0.],  \n",
    "        [12.,  3.,  1.],  \n",
    "        [18.,  1.,  8.]],  \n",
    "        \n",
    "       [[ 2., 21.,  0.],  \n",
    "        [12.,  3.,  1.],  \n",
    "        [18.,  1.,  8.],  \n",
    "        [11., 21., 17.],  \n",
    "        [ 0.,  1.,  0.]],  \n",
    "        \n",
    "       [[18.,  1.,  8.],  \n",
    "        [11., 21., 17.],  \n",
    "        [ 0.,  1.,  0.],  \n",
    "        [ 6.,  0.,  0.],  \n",
    "        [10.,  2.,  0.]],  \n",
    "        \n",
    "       [[ 0.,  1.,  0.],  \n",
    "        [ 6.,  0.,  0.],  \n",
    "        [10.,  2.,  0.],  \n",
    "        [ 2., 21.,  0.],  \n",
    "        [ 0.,  0.,  0.]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
